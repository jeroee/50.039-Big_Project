{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fantastic-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch , torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from torchvision import models\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "from custom_dataset import Train_Dataset, Valid_Dataset, Test_Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stock-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "features = 64\n",
    "num_layers = 10 # the sequence \n",
    "hidden_size = 32\n",
    "batch_size = 8\n",
    "lr = 0.001\n",
    "epoch = 1\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnGru(nn.Module):\n",
    "    def __init__(self,features,num_layers,hidden_size,batch_size):\n",
    "        super(CnnGru,self).__init__()\n",
    "        self.features = features\n",
    "        self.num_layers = num_layers # the sequence \n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # CNN\n",
    "        self.conv2d_1 = nn.Conv2d(3, 16, 3, 1, 1) # 224 x224\n",
    "        self.conv2d_2 = nn.Conv2d(16, 32, 3, 1, 1) # 112 x112\n",
    "        self.conv2d_3 = nn.Conv2d(32, 64, 3, 1, 1) # \n",
    "\n",
    "        self.maxPool2d_1 = nn.MaxPool2d((2, 2))\n",
    "        self.maxPool2d_2 = nn.MaxPool2d((2, 2))\n",
    "        self.maxPool2d_3 = nn.MaxPool2d((2, 2))\n",
    "\n",
    "        self.flatten_1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(50176,features)\n",
    "\n",
    "        # RNN\n",
    "        self.grucell = nn.GRUCell(input_size=features, hidden_size=hidden_size) #, num_layers = num_layers, batch_first = True)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  \n",
    "        \n",
    "    def forward_cnn(self, x: torch.Tensor):\n",
    "        x = F.relu(self.conv2d_1(x))\n",
    "        x = self.maxPool2d_1(x)\n",
    "        x = F.relu(self.conv2d_2(x))\n",
    "        x = self.maxPool2d_2(x)\n",
    "        x = F.relu(self.conv2d_3(x))\n",
    "        x = self.maxPool2d_3(x)\n",
    "        x = self.flatten_1(x)\n",
    "        x = self.fc1(x) \n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    def forward_rnn(self, x: torch.Tensor):\n",
    "        output = []\n",
    "#         h0 = torch.zeros(self.num_layers,x.size(0),self.hidden_size).to(device)\n",
    "#         print(f'input in rnn:{x.shape}')\n",
    "#         print(f'input of h0: {h0.shape}')\n",
    "#         out,_ = self.gru(x,h0)\n",
    "#         print(f'out shape:{out.shape}')\n",
    "#         out = out.reshape(out.shape[0],-1)\n",
    "#         out = self.fc2(out)\n",
    "#         print(f'rnn output:{out.shape}')\n",
    "#         out = torch.squeeze(out)\n",
    "#         out = out.permute(1,0)\n",
    "#         print(f'reshape out shape: {out.shape}')\n",
    "\n",
    "        #h0 = torch.zeros(x.size(0),self.hidden_size).to(device)\n",
    "        h0 = torch.zeros(8,self.hidden_size).to(device)\n",
    "        \n",
    "        #print(\"ho: \", h0)\n",
    "        for frame in x.split(1,dim=1):\n",
    "           # print(\"frame: \", frame)\n",
    "            frame = torch.squeeze(frame)\n",
    "#             print(f'each frame: {frame.shape}')\n",
    "            h0 = self.grucell(frame,h0)\n",
    "            out =  self.fc2(h0)\n",
    "            output += [out]\n",
    "        output = torch.cat(output, dim=1)\n",
    "#         print(f'output shape:{output.shape}')\n",
    "        # 8x10x1\n",
    "        return output\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        batch_size, timesteps, C, H, W = x.size()\n",
    "        gru_in = torch.zeros(batch_size, timesteps, self.features).to(device)\n",
    "#         print(f'x.shape is:{x.shape}')\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            temp = x[:,i,:,:,:]\n",
    "#             print(f'temp shape: {temp.shape}')\n",
    "            temp = self.forward_cnn(temp)\n",
    "#             print(f'cnn output: {temp.shape}')\n",
    "            gru_in[:,i,:] = temp\n",
    "            \n",
    "#         print(f'gru_in: {gru_in}')  \n",
    "#         print(f'gru_in shape: {gru_in.shape}')\n",
    "        \n",
    "        output = self.forward_rnn(gru_in)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assumed-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Train_Dataset()\n",
    "valid_dataset = Valid_Dataset()\n",
    "test_dataset = Test_Dataset()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True)\n",
    "print_every = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "least-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(train_loader)\n",
    "# f, a, v = dataiter.next()\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "successful-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_arousal(model, validloader, criterion, device):\n",
    "    test_loss = 0\n",
    "\n",
    "    for f,a,v in validloader:\n",
    "        f,a,v = f.to(device), a.to(device), v.to(device)\n",
    "\n",
    "        output = model.forward(f)\n",
    "        test_loss += criterion(output, a).item()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "great-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arousal(model, n_epochs=5):\n",
    "    print(f'Training custom CNN-GRU model to predict arousal values')\n",
    "    print(f'total epochs: {n_epochs}')\n",
    "    start = time.time()\n",
    "    model_name = 'arousal model'\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    steps = 0 \n",
    "    train_loss = 0\n",
    "    val_loss_lst=[]\n",
    "    train_loss_lst=[]\n",
    "    Singapore = pytz.timezone('Asia/Singapore')\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        batch = 1\n",
    "        for frames, arousal, valence in train_loader:\n",
    "            print(f'epoch:{epoch} batch:{batch}')\n",
    "            frames, arousal, valence = frames.to(device),arousal.to(device),valence.to(device)\n",
    "            steps+=1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            print(frames.shape)\n",
    "            output = model.forward(frames)\n",
    "#             print(f'output is: {output}')\n",
    "            # getting loss\n",
    "            loss = criterion(output, arousal)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # At the end of every epoch ... (print_every is the length of train_loader)\n",
    "            if steps % print_every == 0:\n",
    "                # Eval mode\n",
    "                model.eval()\n",
    "                # Turn off gradients for validation\n",
    "                with torch.no_grad():\n",
    "                    val_loss = validation_arousal(model, val_loader, criterion, device)\n",
    "\n",
    "                print(\"Epoch: {}/{} - \".format(epoch, n_epochs),\n",
    "                      \"Time: {} \".format(datetime.now(Singapore)),\n",
    "                      \"Training Loss: {:.3f} - \".format(train_loss/len(train_loader)),\n",
    "                      \"Validation Loss: {:.3f} - \".format(val_loss/len(val_loader)))               \n",
    "                    \n",
    "#                 print(\"Epoch: {}/{} Train Loss: {:.6f} Validation Loss: {:.6f}\".format(epoch, n_epochs, train_loss/len(train_loader), val_loss/len(val_loader)))\n",
    "#                 if accuracy > best_accuracy:\n",
    "#                     best_accuracy = accuracy\n",
    "#                     torch.save(model.state_dict(), \"model.pth\")\n",
    "                                                  \n",
    "                val_loss_lst.append(val_loss/len(val_loader))\n",
    "                train_loss_lst.append(train_loss/len(train_loader))\n",
    "                train_loss = 0\n",
    "            batch+=1\n",
    "    \n",
    "    print('model:', model_name,'- epochs:', n_epochs)\n",
    "    print(f\"Run time: {(time.time() - start)/60:.3f} min\")\n",
    "    \n",
    "    return model, train_loss_lst, val_loss_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "essential-polymer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training custom CNN-GRU model to predict arousal values\n",
      "total epochs: 1\n",
      "epoch:1 batch:1\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:2\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:3\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:4\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:5\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:6\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:7\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:8\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:9\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:10\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:11\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:12\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:13\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:14\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:15\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:16\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:17\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:18\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:19\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:20\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:21\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:22\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:23\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:24\n",
      "torch.Size([8, 10, 3, 224, 224])\n",
      "epoch:1 batch:25\n",
      "torch.Size([6, 10, 3, 224, 224])\n",
      "Epoch: 1/1 -  Time: 2021-05-03 16:00:46.482147+08:00  Training Loss: 0.095 -  Validation Loss: 0.061 - \n",
      "model: arousal model - epochs: 1\n",
      "Run time: 6.376 min\n"
     ]
    }
   ],
   "source": [
    "arousal_model, train_lost, val_lost = train_arousal(model = CnnGru(features,num_layers,hidden_size,batch_size), n_epochs = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_lost)\n",
    "print(val_lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "model_name = 'arousal train'\n",
    "e = [i for i in range(1, epoch+1)]\n",
    "print(e)\n",
    "#     train_loss = loss_acc[0]\n",
    "#     val_loss = loss_acc[1]       \n",
    "plt.plot(e,train_lost, label='Training Loss')\n",
    "plt.plot(e,val_lost, label='Validation Loss')\n",
    "plt.xticks(np.arange(min(e), max(e)+1, 1.0))\n",
    "plt.legend()\n",
    "plt.title(f'{model_name} loss',color='black')\n",
    "plt.xlabel('epoch',color='black')\n",
    "plt.ylim(ymin=0)\n",
    "plt.ylabel('loss',color='black')\n",
    "plt.tick_params(colors='black')\n",
    "# plt.savefig(loss_graph,dpi=100,bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accompanied-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0110, 0.0585, 0.0585, 0.0645, 0.0700, 0.0385,\n",
      "        0.0385])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c02a04fee5c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marousal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marousal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marousal_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jeroe\\documents\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-eb94241cd3d1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mgru_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m#         print(f'x.shape is:{x.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "# for frame, arousal, valence in test_loader:\n",
    "#     print(arousal[0])\n",
    "#     pred = arousal_model(frame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mounted-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0015,  0.0217,  0.0298,  0.0335,  0.0140,  0.0450,  0.0590,  0.0450,\n",
      "          0.0510,  0.0630],\n",
      "        [-0.2195, -0.1995, -0.3235, -0.5670, -0.5670, -0.1060, -0.4200, -0.4200,\n",
      "         -0.4320, -0.4320],\n",
      "        [ 0.0980,  0.0220, -0.0340, -0.1050, -0.1615, -0.1930, -0.2475, -0.1645,\n",
      "         -0.0310,  0.3650],\n",
      "        [ 0.1330,  0.1880,  0.1090,  0.2190,  0.3380,  0.1090, -0.0550,  0.1880,\n",
      "          0.2750,  0.2670],\n",
      "        [ 0.1400,  0.0770,  0.2430,  0.1400,  0.1250,  0.1250,  0.2430,  0.2430,\n",
      "          0.0930,  0.2110],\n",
      "        [ 0.1030,  0.0810,  0.0655,  0.0855,  0.0735,  0.0455,  0.0385,  0.0935,\n",
      "          0.1090,  0.1010],\n",
      "        [ 0.1560,  0.3140,  0.2750,  0.2270,  0.2040,  0.1960,  0.0770,  0.0460,\n",
      "          0.0380, -0.0070],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0110,  0.0585,  0.0585,  0.0645,  0.0700,\n",
      "          0.0385,  0.0385]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "f, a, v = dataiter.next()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "present-maine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fuzzy-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 224, 224])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = f.to(device)\n",
    "f[0].shape\n",
    "#arousal_model(f[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "completed-parker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 1, 3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for frame in f[0:1].split(1,dim=1):\n",
    "    print(frame.shape)\n",
    "    frame = torch.squeeze(frame)\n",
    "    print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "existing-macintosh",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c061d1702dc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marousal_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jeroe\\documents\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-eb94241cd3d1>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#         print(f'gru_in shape: {gru_in.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgru_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-eb94241cd3d1>\u001b[0m in \u001b[0;36mforward_rnn\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#             print(f'each frame: {frame.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mh0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrucell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeroe\\documents\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeroe\\documents\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeroe\\documents\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_input\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m             raise RuntimeError(\n\u001b[0;32m    792\u001b[0m                 \"input has inconsistent input_size: got {}, expected {}\".format(\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "arousal_model(f[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-volunteer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
